* 輸入是向量序列
	* 文字處理
		* one-hot encoding: 一個很長的向量，長度跟世界上存在的詞彙的數量一樣多
		* word embedding: 給每一個詞彙一個向量，這個向量是包含語義訊息的，而一個句子就是一組長度不一的向量
	* 聲音信號處理
		* 會把一段聲音訊號取一個範圍，這個範圍叫做一個窗口（window），把該窗口裡面的訊息描述成一個向量，這個向量稱為一幀（frame）
	* 圖
		* eg. social network, molecule
* 輸出有三種可能性
	1. 每一個向量都有一個對應的標簽 → 詞性標註（POS tagging）：機器會自動決定每一個詞彙的詞性，判斷該詞是名詞還是動詞還是形容詞等等
	2. 一組向量序列輸出一個標簽 → 文本情感分析：給機器看一段話，模型要決定這段話是積極的（positive）還是消極的（negative）
	3. 模型自行決定輸出多少個標籤 → 輸入是 N 個向量，輸出可能是 N′ 個標簽，而N′ 是機器自己決定的。此種任務被稱作序列到序列（**Sequence to Sequence**，Seq2Seq），如翻譯、語音辨識
* Self Attention Model
	* 考慮整個序列的所有向量，綜合向量序列整體和單個向量個體，得到對每一個向量處理後的向量，將這些向量個別連接一個 FC，FC 可以專注於處理這一個位置的向量，得到對應結果
	* 輸入：一串的 vector，這些 vector 可能是整個 network 的 input，也可能是某個 hidden layer 的output
	* 輸出：處理 input 以後，每一個 b 都是考慮了所有的 a 以後才生成出來的
	* 步驟
		1. 根據 $a^1$ 這個向量找出跟其他向量的相關程度 $\alpha$
		2. 藉由一個計算 attention 的模組來得到 $α$。（q = query、k = key）